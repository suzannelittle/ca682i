{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "2.1.6 Reading and formatting data",
      "provenance": [],
      "private_outputs": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/suzannelittle/ca682i/blob/master/notebooks/2_1_6_Reading_and_formatting_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4ziSoKC3kDW"
      },
      "source": [
        "# Reading and formatting data\n",
        "\n",
        "A significant part of any data-driven project occurs in the data gathering and data processing phases. Here we see how a Jupyter notebook and python libraries can be used to read in, document and explore a simple dataset in CSV format.\n",
        "\n",
        "To do this exercise, first make a copy of this notebook to your own account. If you are viewing it in Colab (colab.research.google) then go to the File menu and choose \"Save a copy in drive\".\n",
        "\n",
        "---  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YDqgAioS7NVu"
      },
      "source": [
        "## Markdown\n",
        "\n",
        "Take a look at this cell by double-clicking on it. It (and the other text cells) are made with [Markdown](https://colab.research.google.com/notebooks/markdown_guide.ipynb).\n",
        "\n",
        "You can make a list:\n",
        "* of  \n",
        "* items\n",
        "* like  \n",
        "* this\n",
        "\n",
        "And many more formatting options. This is useful for documenting your work.\n",
        "\n",
        "Edit this cell to fill in your details below.\n",
        "\n",
        "**Name:**  \n",
        "**Date:**  \n",
        "\n",
        "---  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZYO2tgIblBr"
      },
      "source": [
        "# Reading data using Pandas    \n",
        "Some examples of data I/O using pandas in Jupyter notebooks    \n",
        "https://pandas.pydata.org/pandas-docs/stable/io.html\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0N2OFb_nblBs"
      },
      "source": [
        "import pandas as pd  # always do this in python, you can now use functions from the pandas library (pd.)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ct5_p1TVblBw"
      },
      "source": [
        "## read_csv    \n",
        "https://pandas.pydata.org/pandas-docs/stable/io.html#io-read-csv-table\n",
        "\n",
        "Read the DataSampler.csv file into a pandas dataframe object. Convention is to call dataframes `df`.    \n",
        "The main argument to `read_csv` is the path to the file. This can be a local path (ie, you've downloaded DataSampler.csv) or a url. The local version needs to be in the same directory as your notebook for the following code to work."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8bfvIM9DblBw"
      },
      "source": [
        "path_to_sampler = \"https://raw.githubusercontent.com/suzannelittle/ca682i/master/data/sampler/DataSampler.csv\"\n",
        "df_csv = pd.read_csv(path_to_sampler)  # look at the other arguments to read_csv. Anything you could add?"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-aKDWKJ6blBz"
      },
      "source": [
        "df_csv.head(10)  # show the first 10 lines"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l4NYY5FDblB4"
      },
      "source": [
        "df_csv.tail() # show the last 5 lines"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p4gVs8nmblB6"
      },
      "source": [
        "df_csv.shape  # find out how many rows and columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K_HAaB8jblB9"
      },
      "source": [
        "So the DataSampler has 151 entries (rows) with 9 attributes (columns) each. What are the attributes? The .columns attribute will give a list of the column headings."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fbGqbp49blB9"
      },
      "source": [
        "df_csv.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "12xguX3mCjmD"
      },
      "source": [
        "To see other useful information about the dataframe, try the .info() function to get the data type for each column. Do these match what you would expect? A good overview of data types in pandas - https://pbpython.com/pandas_dtypes.html.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1esxVlCDUwr"
      },
      "source": [
        "df_csv.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSu2opksD1kY"
      },
      "source": [
        "These look fairly correct except that column A is a datetime value. We'll look again at this dataset when we cover data cleaning in Topic 3 of this course."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AL-9IJ1A8yRF"
      },
      "source": [
        "Finally let's use the [describe](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.describe.html) function to calculate some descriptive statistics about our data. Remember that you can't apply these to qualitative attributes. Before you run the next code cell, which columns should you be able to apply descriptive statistics to?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1KeMhll88reI"
      },
      "source": [
        "df_csv.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mY0eutxbIlSR"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "irVXOZK5blCA"
      },
      "source": [
        "## read_excel     \n",
        "\n",
        "XLS or XLSX files are spreadsheet documents formatted for Microsoft Excel. Recall that this is a proprietary, but basically text, format. The actual file is an archive containing mostly XML files that describe the appearance and functionality and contain the data. This means that sometimes other libraries (like pandas) that support the format will fail when the format is changed or updated in some way.\n",
        "\n",
        "`!pip install --upgrade openpyxl`\n",
        "\n",
        "The sample data comes from [Principles of Economics](https://principlesofeconometrics.com/poe5/poe5.html) and there are [data definition files](http://www.principlesofeconometrics.com/poe5/data/def/nasa.def) available (structured metadata)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# old xls format from https://file-examples.com/index.php/sample-documents-download/sample-xls-download/\n",
        "try:\n",
        "  test_1 = pd.read_excel(\"https://github.com/suzannelittle/ca682i/raw/refs/heads/master/data/file_example_XLS_10.xls\")\n",
        "  print(\"Able to read old xls version\")\n",
        "except ValueError as v:\n",
        "  print(\"Unable to read old xls file\")\n",
        "  print(\"ValueError: \", v)\n",
        "\n",
        "# xlsx with document properties error from https://principlesofeconometrics.com/poe5/poe5.html\n",
        "try:\n",
        "  test_2 = pd.read_excel(\"https://github.com/suzannelittle/ca682i/raw/refs/heads/master/data/nasa.xlsx\")\n",
        "  print(\"Able to read xlsx with metadata error\")\n",
        "except TypeError as t:\n",
        "  print(\"Unable to read xlsx file due to properties error\")\n",
        "  print(\"TypeError: \", t)"
      ],
      "metadata": {
        "id": "n2-QpCIiJk-z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You may get the following error for test_2:\n",
        "\n",
        "> `TypeError: WorksheetProperties.__init__() got an unexpected keyword argument 'synchVertical'`\n",
        "\n",
        "Try the following to see the cause:\n",
        "1. Download the excel file to your computer\n",
        "2. Either change the file extension to .zip (windows) or use something like tar to extract the files from the XSLX container.\n",
        "3. Go to `xl/worksheets/sheet1.xml` and look at the 2nd line for the `synchVertical=\"1\"` entry.  \n",
        "\n",
        "The correct name for the property is `syncVertical` (without the 'h'). Some programmes output the incorrect name and while previous versions of libraries to read the format would ignore this error, some recent ones will refuse to load the data.\n",
        "\n",
        "I opened the file in Excel and saved it to a new file name which fixed the problem.\n",
        "\n",
        "[This stackoverflow post](https://stackoverflow.com/questions/67925727/read-in-xlsx-in-pandas-with-openpyxl) has some background information."
      ],
      "metadata": {
        "id": "YDW6LW3rJ1l4"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fhSgFvSQblCB"
      },
      "source": [
        "# This excel file *should* work!\n",
        "df_excel = pd.read_excel(\"https://github.com/suzannelittle/ca682i/raw/refs/heads/master/data/nasa_adj.xlsx\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ABoULiTy9Yos"
      },
      "source": [
        "Using the function .head() is always a good first step when loading in a new dataset. This helps you to see if the data has been read in correctly and has the type of values you expect."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WzA6R0DsblCD"
      },
      "source": [
        "df_excel.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8unfQmSA9hn_"
      },
      "source": [
        "Checking the shape attribute of the data is a good next check to see if the data is the size you expect it to be."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Os8GET2sblCG"
      },
      "source": [
        "df_excel.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JVCYdTQvJbTl"
      },
      "source": [
        "df_excel.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fkTbi4stJggf"
      },
      "source": [
        "Notice that this dataset has got the dateid01 column as a datetime64 type. Why do you think that this column has the correct attribute while column A in the Data Sampler dataset does not?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yJqLdxI0C7-m"
      },
      "source": [
        "df_excel.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dp85ol-XblCL"
      },
      "source": [
        "## read_json    \n",
        "We'll talk about JSON more when we look at JavaScript for data visualisation. But here is another example of reading in a different file format. You can view the raw JSON data at https://raw.githubusercontent.com/corysimmons/colors.json/master/colors.json.   "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pg3uznnCblCM"
      },
      "source": [
        "df_json = pd.read_json(\"https://raw.githubusercontent.com/corysimmons/colors.json/master/colors.json\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9KkYNstNblCQ"
      },
      "source": [
        "df_json.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yx69lhpyblCV"
      },
      "source": [
        "df_json.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kmua7SisA_fo"
      },
      "source": [
        "This dataset contains the RGB colour values for the named web colours. The shape is a bit annoying. Lets rotate the dataframe so that each row is a colour using the transpose function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "adf0f58TblCZ"
      },
      "source": [
        "df_json.transpose().head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NbVEwN8pBQwV"
      },
      "source": [
        "df_json.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqnQ9rhmBY5Z"
      },
      "source": [
        "Hang on! Why is the dataset shape still the same?\n",
        ".transpose returns the transposed data frame without altering the original data object. Let's try again and save the transposed data frame. There's also a shortcut .T which does the same thing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VoTSHN9VBVqe"
      },
      "source": [
        "df_json_T = df_json.T"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "an2j40XRB1WF"
      },
      "source": [
        "df_json_T.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HB5OZ6VFCWVI"
      },
      "source": [
        "Notice that the shape has now changed and the data frame has 149 rows and 4 columns (red, green, blue and intensity)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_lEAj413B2sF"
      },
      "source": [
        "df_json_T.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MJF4g1UtJ9rh"
      },
      "source": [
        "---  \n",
        "\n",
        "There are other ways to get data into a dataframe. Take a look at the pandas [I/O documentation](https://pandas.pydata.org/pandas-docs/stable/user_guide/io.html) and see what formats you recognise and if you can find another one to try."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GqWzxfGuLMZg"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}